{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate and Epoch Sensitivity\n",
        "We test how learning rate and number of epochs affect convergence and generalization.\n",
        "Goal: show stable vs unstable optimization regimes."
      ],
      "metadata": {
        "id": "zy9m5qn3XkU1"
      },
      "id": "zy9m5qn3XkU1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data + Model Builder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train / 255.0).reshape(-1, 784)\n",
        "X_test  = (X_test / 255.0).reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test  = to_categorical(y_test, 10)\n",
        "\n",
        "def build_mlp(depth: int, width: int, lr: float):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(width, activation=\"relu\", input_shape=(784,)))\n",
        "    for _ in range(depth - 1):\n",
        "        model.add(Dense(width, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "    model.compile(optimizer=Adam(learning_rate=lr),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "reVWTrdHXlJx"
      },
      "id": "reVWTrdHXlJx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate Experiment: Fixed Architecture\n",
        "depth = 2\n",
        "width = 128\n",
        "lrs = [0.001, 0.01, 0.1, 1.0]\n",
        "EPOCHS = 10\n",
        "BATCH = 128\n",
        "\n",
        "histories = {}\n",
        "\n",
        "for lr in lrs:\n",
        "    print(\"Training lr =\", lr)\n",
        "    model = build_mlp(depth, width, lr)\n",
        "    hist = model.fit(X_train, y_train, validation_split=0.2,\n",
        "                     epochs=EPOCHS, batch_size=BATCH, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    histories[lr] = (hist.history, test_acc, test_loss)\n",
        "    print(\"test_acc =\", round(test_acc, 4), \"test_loss =\", round(test_loss, 4))"
      ],
      "metadata": {
        "id": "EIztDDIQX5Ac"
      },
      "id": "EIztDDIQX5Ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "plt.figure()\n",
        "for lr in lrs:\n",
        "    h, _, _ = histories[lr]\n",
        "    plt.plot(h[\"val_loss\"], marker=\"o\", label=f\"lr={lr}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.title(\"Learning Rate Sensitivity (Val Loss)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JfGzEINPYDpZ"
      },
      "id": "JfGzEINPYDpZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Epoch experiment (fixed lr)\n",
        "epochs_list = [5, 10, 20, 40]\n",
        "lr = 0.001\n",
        "\n",
        "epoch_results = []\n",
        "for ep in epochs_list:\n",
        "    model = build_mlp(depth=2, width=128, lr=lr)\n",
        "    hist = model.fit(X_train, y_train, validation_split=0.2,\n",
        "                     epochs=ep, batch_size=BATCH, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    epoch_results.append((ep, test_acc, test_loss, hist.history[\"val_loss\"][-1]))\n",
        "\n",
        "epoch_results"
      ],
      "metadata": {
        "id": "n58RSJU2YLNZ"
      },
      "id": "n58RSJU2YLNZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot test acc vs epochs\n",
        "eps = [x[0] for x in epoch_results]\n",
        "tacc = [x[1] for x in epoch_results]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(eps, tacc, marker=\"o\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.title(\"Epoch Sensitivity (Test Accuracy)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MOCfm8ZGYTsI"
      },
      "id": "MOCfm8ZGYTsI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}